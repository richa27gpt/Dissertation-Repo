{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ab6d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for basic functions\n",
    "import numpy as np\n",
    "import tkinter\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import datetime as dt\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "# Import libraries for Stock, Currencies and Commodities Data extraction\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.foreignexchange import ForeignExchange\n",
    "import yfinance as yf\n",
    "\n",
    "# Import Libraries for Twitter Sentiment Analysis \n",
    "import re\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "# Import Libraries for ML Algorithm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba78907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get Fortune-500 companies list from Wikipedia\n",
    "table=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "df = table[0]\n",
    "df.to_csv('S&P500-Info.csv')\n",
    "df.to_csv(\"S&P500-Symbols.csv\", columns=['Symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2647b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n",
      "Time Interval\n",
      "'AAPL'\n",
      "AAPL\n",
      "1day\n",
      "'1day'\n"
     ]
    }
   ],
   "source": [
    "##Create GUI box to select Stock ticker\n",
    "window = tkinter.Tk()\n",
    "\n",
    "window.geometry(\"%dx%d+%d+%d\" % (330, 80, 200, 150))\n",
    "window.title(\"Fortune 500 Stocks\")\n",
    "\n",
    "# Dropdown menu options\n",
    "dropdown = df['Symbol'].tolist()\n",
    "dd_timeint = ('1min','5min','60min', '1day')\n",
    "\n",
    "#updates text\n",
    "def func(selected_item):\n",
    "  print(repr(selected_item.strip()))\n",
    "\n",
    "# Close window after selecting 2nd dropdown value\n",
    "def func2(selected_item):\n",
    "  print(repr(selected_item.strip()))\n",
    "  window.destroy()  # close window\n",
    "\n",
    "#create a dropdown list for Ticker Selection\n",
    "var = tkinter.StringVar()\n",
    "var.set('Ticker Name')\n",
    "p = tkinter.OptionMenu(window, var, *dropdown, command=func)\n",
    "\n",
    "p.pack()\n",
    "display = tkinter.Label(window)\n",
    "display.pack()\n",
    "\n",
    "#create a dropdown list for Time Interval\n",
    "var2 = tkinter.StringVar()\n",
    "var2.set('Time Interval')\n",
    "p = tkinter.OptionMenu(window, var2, *dd_timeint, command=func2)\n",
    "\n",
    "p.pack()\n",
    "display = tkinter.Label(window)\n",
    "display.pack()\n",
    "\n",
    "# on change dropdown value\n",
    "def change_dropdown(*args):\n",
    "    print( var.get() )\n",
    "    print( var2.get() )\n",
    "\n",
    "# link function to change dropdown\n",
    "var.trace('w', change_dropdown)\n",
    "var2.trace('w', change_dropdown)\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "468b7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Average Class setup\n",
    "class MovingAverage():\n",
    "    def __init__(self, closingPrice):\n",
    "        self.data = pd.DataFrame(closingPrice) \n",
    "\n",
    "# Calculating EMA\n",
    "    def EMA(self, averaging_length=50):\n",
    "        ret = self.data.ewm(\n",
    "            span=averaging_length, \n",
    "            adjust=False).mean()\n",
    "        return ret.rename(columns={'4. close': 'EMA'})\n",
    "\n",
    "# Return Components of MACD\n",
    "    def MACD(self, a=12, b=26, c=9):\n",
    "        MACD_line = self.EMA(a) - self.EMA(b)\n",
    "        signal_line = MACD_line.ewm(span=c, adjust=False).mean()\n",
    "        histogram = MACD_line - signal_line\n",
    "        return MACD_line, signal_line, histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d538f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseriesfunc(ticker_name, data_interval):\n",
    "\n",
    "    ## Use API key from Alpha Vantage\n",
    "    api_key = 'T99XAOQH3CAGPE4V'\n",
    "\n",
    "    ## Generate Alpha Vantage time series object\n",
    "    ts = TimeSeries(key=api_key, output_format='pandas')\n",
    "    app = ForeignExchange(key=api_key, output_format='pandas')\n",
    "        \n",
    "    ## Retrieve data for past 60 days\n",
    "    if data_interval == '1day':\n",
    "        #Fetch Stock daily data (past 60 days)\n",
    "        data, meta_data = ts.get_daily(ticker_name, outputsize = 'compact') \n",
    "        \n",
    "        #Fetch currency data (past 60 days)\n",
    "        GBP_data, GBP_metadata = app.get_currency_exchange_daily(from_symbol = 'USD',to_symbol = 'GBP', outputsize = 'compact' )\n",
    "        EUR_data, EUR_metadata = app.get_currency_exchange_daily(from_symbol = 'USD',to_symbol = 'EUR', outputsize = 'compact' )\n",
    "\n",
    "        #Fetch Gold and oil daily data from Yahoo Finance\n",
    "        if data_interval == '60min':\n",
    "            intvl = data_interval[0:3]\n",
    "        else:\n",
    "            intvl = data_interval[0:2]\n",
    "\n",
    "        comm = yf.download(['BTC-USD','GLD','CL=F'] , period=\"6mo\", interval=intvl, auto_adjust=True)  \n",
    "        comm = comm[['Close']]\n",
    "        comm.columns = [col[1] for col in comm.columns]    \n",
    "        Gold_CP = comm['GLD']\n",
    "        Oil_CP = comm['CL=F']\n",
    "    \n",
    "    else:   \n",
    "        data, meta_data = ts.get_intraday(ticker_name, interval = data_interval, outputsize = 'full')\n",
    "\n",
    "        # #Fetch currency data (past 60 days)\n",
    "        GBP_data, GBP_metadata = ts.get_intraday(symbol = \"USDGBP\", interval=data_interval, outputsize = 'full')\n",
    "        EUR_data, EUR_metadata = ts.get_intraday(symbol = \"USDEUR\", interval=data_interval, outputsize = 'full')\n",
    "\n",
    "        # #Fetch commodity data (past 60 days)\n",
    "        GLD_data, GLD_metadata = ts.get_intraday(symbol = \"GLD\", interval=data_interval, outputsize = 'full') \n",
    "        Oil_data, Oil_metadata = ts.get_intraday(symbol = \"CL\", interval=data_interval, outputsize = 'full')\n",
    "\n",
    "        Gold_CP = GLD_data['4. close']\n",
    "        Oil_CP = Oil_data['4. close']\n",
    "\n",
    "\n",
    "    GBP_CP = GBP_data['4. close']\n",
    "    EUR_CP = EUR_data['4. close']\n",
    "\n",
    "    data['date_time'] = data.index\n",
    "    data['date_only'] = data['date_time'].dt.date\n",
    "\n",
    "    # Calculate consecutive days price difference (Delta) for all - commodities,currencies and closing price of stock.\n",
    "    ## Day1 - Day2\n",
    "    Delta_GBP = GBP_CP.diff()\n",
    "    Delta_EUR = EUR_CP.diff()\n",
    "    Delta_Gold = Gold_CP.diff()\n",
    "    Delta_Oil = Oil_CP.diff()\n",
    "\n",
    "    ## Percentage changes in all fields\n",
    "    OpeningPrice = data['1. open']\n",
    "    Delta_OP = OpeningPrice.pct_change()\n",
    "\n",
    "    high = data['2. high']\n",
    "    Delta_high = high.pct_change()\n",
    "\n",
    "    low = data['3. low']\n",
    "    Delta_low = low.pct_change()\n",
    "    \n",
    "    closingPrice = data['4. close']\n",
    "    Delta_CP = closingPrice.diff()\n",
    "    \n",
    "    volume = data['5. volume']\n",
    "    Delta_Vol = volume.pct_change()\n",
    "    \n",
    "    mean = (( high + low ) / 2 )\n",
    "    \n",
    "    # Calculating Moving Average components\n",
    "    MACD_indicator = MovingAverage(closingPrice)\n",
    "    MACD_line, signal_line, histogram = MACD_indicator.MACD()\n",
    "\n",
    "    # Convert data into dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('Extracted Data before feature engineering.csv')\n",
    "\n",
    "    # Add extra detailed columns (features) to the data\n",
    "    df['Delta_OP'] = Delta_OP\n",
    "    df['Delta_high'] = Delta_high\n",
    "    df['Delta_low'] = Delta_low\n",
    "    df['Delta_Vol'] = Delta_Vol\n",
    "    df['Delta_CP'] = Delta_CP\n",
    "    df['MeanPrice'] = mean\n",
    "    df['MACD Line'] = MACD_line\n",
    "    df['Signal Line'] = signal_line\n",
    "    df['Histogram'] = histogram\n",
    "    df['GBP_CP'] = GBP_CP     \n",
    "    df['EUR_CP'] = EUR_CP  \n",
    "    df['Gold_CP'] = Gold_CP\n",
    "    df['Oil_CP'] = Oil_CP\n",
    "    df['Delta_GBP'] = Delta_GBP     \n",
    "    df['Delta_EUR'] = Delta_EUR  \n",
    "    df['Delta_Gold'] = Delta_Gold\n",
    "    df['Delta_Oil'] = Delta_Oil\n",
    "\n",
    "    # Fill empty Data with the column Mean value\n",
    "    df['Delta_EUR'].fillna((df['Delta_EUR'].mean()), inplace=True)\n",
    "    df['Delta_GBP'].fillna((df['Delta_GBP'].mean()), inplace=True)\n",
    "    df['Delta_Oil'].fillna((df['Delta_Oil'].mean()), inplace=True)\n",
    "    df['Delta_Gold'].fillna((df['Delta_Gold'].mean()), inplace=True)    \n",
    "    df['Delta_CP'].fillna((df['Delta_CP'].mean()), inplace=True)\n",
    "    df['Delta_OP'].fillna((df['Delta_OP'].mean()), inplace=True)\n",
    "    df['Delta_high'].fillna((df['Delta_high'].mean()), inplace=True)\n",
    "    df['Delta_low'].fillna((df['Delta_low'].mean()), inplace=True)\n",
    "    df['Delta_Vol'].fillna((df['Delta_Vol'].mean()), inplace=True)\n",
    "\n",
    "    # Replace the difference with 0 or 1 depending upon their negative or positive value\n",
    "    ## One-hot encoding\n",
    "    df.loc[df.Delta_CP > 0, \"Delta_CP\"] = 1\n",
    "    df.loc[df.Delta_CP < 0, \"Delta_CP\"] = 0\n",
    "\n",
    "    df.loc[df.Delta_GBP > 0, \"Delta_GBP\"] = 1\n",
    "    df.loc[df.Delta_GBP < 0, \"Delta_GBP\"] = 0\n",
    "\n",
    "    df.loc[df.Delta_EUR > 0, \"Delta_EUR\"] = 1\n",
    "    df.loc[df.Delta_EUR < 0, \"Delta_EUR\"] = 0\n",
    "\n",
    "    df.loc[df.Delta_Gold > 0, \"Delta_Gold\"] = 1\n",
    "    df.loc[df.Delta_Gold < 0, \"Delta_Gold\"] = 0\n",
    "\n",
    "    df.loc[df.Delta_Oil > 0, \"Delta_Oil\"] = 1\n",
    "    df.loc[df.Delta_Oil < 0, \"Delta_Oil\"] = 0\n",
    "\n",
    "    #Copy commodities data into new column for addition of old data columns\n",
    "    df['old_gold_1'] = df['Delta_Gold']\n",
    "    df['old_oil_1'] = df['Delta_Oil']\n",
    "    df['old_GBP_1'] = df['Delta_GBP']\n",
    "    df['old_EUR_1'] = df['Delta_EUR']\n",
    "\n",
    "    df['old_gold_2'] = df['Delta_Gold']\n",
    "    df['old_oil_2'] = df['Delta_Oil']\n",
    "    df['old_GBP_2'] = df['Delta_GBP']\n",
    "    df['old_EUR_2'] = df['Delta_EUR']\n",
    "\n",
    "    df['old_gold_3'] = df['Delta_Gold']\n",
    "    df['old_oil_3'] = df['Delta_Oil']\n",
    "    df['old_GBP_3'] = df['Delta_GBP']\n",
    "    df['old_EUR_3'] = df['Delta_EUR']\n",
    "\n",
    "    # Shift column up by 1 days (correlation with 1 day older data)\n",
    "    df.old_gold_1 = df.old_gold_1.shift(-1)\n",
    "    df.old_oil_1 = df.old_oil_1.shift(-1)\n",
    "    df.old_GBP_1 = df.old_GBP_1.shift(-1)\n",
    "    df.old_EUR_1 = df.old_EUR_1.shift(-1)\n",
    "    df['old_gold_1'] = df['old_gold_1'].fillna(df['Delta_Gold'])\n",
    "    df['old_oil_1'] = df['old_oil_1'].fillna(df['Delta_Oil'])\n",
    "    df['old_GBP_1'] = df['old_GBP_1'].fillna(df['Delta_GBP'])\n",
    "    df['old_EUR_1'] = df['old_EUR_1'].fillna(df['Delta_EUR'])\n",
    "\n",
    "    # Shift column up by 2 days (correlation with 2 day older data)\n",
    "    df.old_gold_2 = df.old_gold_2.shift(-2)\n",
    "    df.old_oil_2 = df.old_oil_2.shift(-2)\n",
    "    df.old_GBP_2 = df.old_GBP_2.shift(-2)\n",
    "    df.old_EUR_2 = df.old_EUR_2.shift(-2)\n",
    "    df['old_gold_2'] = df['old_gold_2'].fillna(df['Delta_Gold'])\n",
    "    df['old_oil_2'] = df['old_oil_2'].fillna(df['Delta_Oil'])\n",
    "    df['old_GBP_2'] = df['old_GBP_2'].fillna(df['Delta_GBP'])\n",
    "    df['old_EUR_2'] = df['old_EUR_2'].fillna(df['Delta_EUR'])\n",
    "\n",
    "    # Shift column up by 3 days (correlation with 3 day older data)\n",
    "    df.old_gold_3 = df.old_gold_3.shift(-3)\n",
    "    df.old_oil_3 = df.old_oil_3.shift(-3)\n",
    "    df.old_GBP_3 = df.old_GBP_3.shift(-3)\n",
    "    df.old_EUR_3 = df.old_EUR_3.shift(-3)\n",
    "    df['old_gold_3'] = df['old_gold_3'].fillna(df['Delta_Gold'])\n",
    "    df['old_oil_3'] = df['old_oil_3'].fillna(df['Delta_Oil'])\n",
    "    df['old_GBP_3'] = df['old_GBP_3'].fillna(df['Delta_GBP'])\n",
    "    df['old_EUR_3'] = df['old_EUR_3'].fillna(df['Delta_EUR'])\n",
    "\n",
    "    # Add features from the twitter\n",
    "    if __name__ == \"__main__\":\n",
    "        # Checking Twitter Sentiments\n",
    "        query = [\"Gold OR gold OR crude OR Oil OR USD OR Dollar OR EUR OR Euro OR GBP OR Pound OR Great Britain Pound\"]\n",
    "        tweet_df = main(query, df)\n",
    "\n",
    "        if len(tweet_df) != 0:\n",
    "            df = df.join(tweet_df, how='outer', on='date_only')\n",
    "            df['negative'].fillna((df['negative'].mean()), inplace=True)    \n",
    "            df['neutral'].fillna((df['neutral'].mean()), inplace=True)\n",
    "            df['positive'].fillna((df['positive'].mean()), inplace=True)\n",
    "            df['pos_perc'].fillna((df['pos_perc'].mean()), inplace=True)\n",
    "            df['neg_perc'].fillna((df['neg_perc'].mean()), inplace=True)\n",
    "            df['neut_perc'].fillna((df['neut_perc'].mean()), inplace=True)  \n",
    "            df['total_tw'].fillna((df['total_tw'].mean()), inplace=True)  \n",
    "            df['tw_weight'].fillna((df['tw_weight'].mean()), inplace=True) \n",
    "\n",
    "    df = df[:-3]\n",
    "    \n",
    "    # Data extraction and feature engeering completed.\n",
    "    ## Write the final dataset as an excel file into device\n",
    "    if data_interval == '1min':\n",
    "        df.to_csv(\"Final_Dataset_1min.csv\")\n",
    "    elif data_interval == '5min':\n",
    "        df.to_csv(\"Final_Dataset_5min.csv\")\n",
    "    elif data_interval == '60min':\n",
    "        df.to_csv(\"Final_Dataset_1hr.csv\")\n",
    "    elif data_interval == '1day':        \n",
    "        df.to_csv(\"Final_Dataset_1day.csv\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e2b9531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_threshold(dframe):\n",
    "\n",
    "    df = pd.DataFrame(dframe)\n",
    "\n",
    "    f1_gold = f1_score(df.Delta_CP, df.Delta_Gold, average=None)\n",
    "    f1_oil = f1_score(df.Delta_CP, df.Delta_Oil, average=None)\n",
    "    f1_gbp = f1_score(df.Delta_CP, df.Delta_GBP, average=None)\n",
    "    f1_eur = f1_score(df.Delta_CP, df.Delta_EUR, average=None)\n",
    "\n",
    "    f1_old_gold_1 = f1_score(df.Delta_CP, df.old_gold_1, average=None)\n",
    "    f1_old_oil_1 = f1_score(df.Delta_CP, df.old_oil_1, average=None)\n",
    "    f1_old_gbp_1 = f1_score(df.Delta_CP, df.old_GBP_1, average=None)\n",
    "    f1_old_eur_1 = f1_score(df.Delta_CP, df.old_EUR_1, average=None)\n",
    "\n",
    "    f1_old_gold_2 = f1_score(df.Delta_CP, df.old_gold_2, average=None)\n",
    "    f1_old_oil_2 = f1_score(df.Delta_CP, df.old_oil_2, average=None)\n",
    "    f1_old_gbp_2 = f1_score(df.Delta_CP, df.old_GBP_2, average=None)\n",
    "    f1_old_eur_2 = f1_score(df.Delta_CP, df.old_EUR_2, average=None)\n",
    "\n",
    "    f1_old_gold_3 = f1_score(df.Delta_CP, df.old_gold_3, average=None)\n",
    "    f1_old_oil_3 = f1_score(df.Delta_CP, df.old_oil_3, average=None)\n",
    "    f1_old_gbp_3 = f1_score(df.Delta_CP, df.old_GBP_3, average=None)\n",
    "    f1_old_eur_3 = f1_score(df.Delta_CP, df.old_EUR_3, average=None)\n",
    "    \n",
    "    # Positive predictions (F1-Score) mean for calculation of Threshold Value\n",
    "    threshold = (( f1_gold + f1_oil + f1_gbp + f1_eur ) / 4 )\n",
    "    threshold1 = (( f1_old_gold_1 + f1_old_oil_1 + f1_old_gbp_1 + f1_old_eur_1 ) / 4 )\n",
    "    threshold2 = (( f1_old_gold_2 + f1_old_oil_2 + f1_old_gbp_2 + f1_old_eur_2 ) / 4 )\n",
    "    threshold3 = (( f1_old_gold_3 + f1_old_oil_3 + f1_old_gbp_3 + f1_old_eur_3 ) / 4 )\n",
    "\n",
    "    if f1_gbp[0] < threshold[0]:\n",
    "        df.drop(['Delta_GBP'], axis='columns', inplace=True) #drop column Delta_GBP\n",
    "    if f1_eur[0] < threshold[0]:\n",
    "        df.drop(['Delta_EUR'], axis='columns', inplace=True) #drop column Delta_EUR     \n",
    "    if f1_gold[0] < threshold[0]:\n",
    "        df.drop(['Delta_Gold'], axis='columns', inplace=True) #drop column Delta_Gold\n",
    "    if f1_oil[0] < threshold[0]:\n",
    "        df.drop(['Delta_Oil'], axis='columns', inplace=True) #drop column Delta_Oil\n",
    "\n",
    "    if f1_old_gold_1[0] < threshold1[0]:\n",
    "        df.drop(['old_gold_1'], axis='columns', inplace=True) #drop column old_gold_1\n",
    "    if f1_old_oil_1[0] < threshold1[0]:\n",
    "        df.drop(['old_oil_1'], axis='columns', inplace=True) #drop column old_oil_1\n",
    "    if f1_old_gbp_1[0] < threshold1[0]:\n",
    "        df.drop(['old_GBP_1'], axis='columns', inplace=True) #drop column old_GBP_1\n",
    "    if f1_old_eur_1[0] < threshold1[0]:\n",
    "        df.drop(['old_EUR_1'], axis='columns', inplace=True) #drop column old_EUR_1\n",
    "\n",
    "    if f1_old_gold_2[0] < threshold2[0]:\n",
    "        df.drop(['old_gold_2'], axis='columns', inplace=True) #drop column old_gold_2\n",
    "    if f1_old_oil_2[0] < threshold2[0]:\n",
    "        df.drop(['old_oil_2'], axis='columns', inplace=True) #drop column old_oil_2  \n",
    "    if f1_old_gbp_2[0] < threshold2[0]:\n",
    "        df.drop(['old_GBP_2'], axis='columns', inplace=True) #drop column old_GBP_2\n",
    "    if f1_old_eur_2[0] < threshold2[0]:\n",
    "        df.drop(['old_EUR_2'], axis='columns', inplace=True) #drop column old_EUR_2\n",
    "\n",
    "    if f1_old_gold_3[0] < threshold3[0]:\n",
    "        df.drop(['old_gold_3'], axis='columns', inplace=True) #drop column old_gold_3\n",
    "    if f1_old_oil_3[0] < threshold3[0]:\n",
    "        df.drop(['old_oil_3'], axis='columns', inplace=True) #drop column old_oil_3\n",
    "    if f1_old_gbp_3[0] < threshold3[0]:\n",
    "        df.drop(['old_GBP_3'], axis='columns', inplace=True) #drop column old_GBP_3\n",
    "    if f1_old_eur_3[0] < threshold3[0]:\n",
    "        df.drop(['old_EUR_3'], axis='columns', inplace=True) #drop column old_EUR_3         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fda5855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterClient(object):\n",
    "    '''\n",
    "    Generic Twitter Class for sentiment analysis.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Class constructor or initialization method.\n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console\n",
    "        consumer_key = 'klEqcFpgzV45QseGqY8bF0YUz'\n",
    "        consumer_secret = 'Nr1Au9Va4DiFFPUYWeQvmW2Wc8r5iyVr392eeXmtFgU10NOhWf'\n",
    "        access_token = '1412996250098614275-UGgVUXN72VYbguAdCBAaWQXEazgoZr'\n",
    "        access_token_secret = 'wu29wfJgGRIhBlywCVxmGdqR7kdSoSnMjLRcPjxuLrcxx'\n",
    "\n",
    "        # attempt authentication\n",
    "        try:\n",
    "            # create OAuthHandler object\n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            # set access token and secret\n",
    "            self.auth.set_access_token(access_token, access_token_secret)\n",
    "            # create tweepy API object to fetch tweets\n",
    "            self.api = tweepy.API(self.auth)\n",
    "        except:\n",
    "            print(\"Error: Authentication Failed\")\n",
    "\n",
    "    def clean_tweet(self, tweet):\n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        '''\n",
    "        Utility function to classify sentiment of passed tweet\n",
    "        using textblob's sentiment method\n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        # set sentiment\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def get_tweets(self, query, count, dfdate):\n",
    "        '''\n",
    "        Main function to fetch tweets and parse them.\n",
    "        '''\n",
    "        # empty list to store parsed tweets\n",
    "        tweets = []\n",
    "        \n",
    "        dfdate = dfdate.replace(' ', '')\n",
    "        sdate = datetime.strptime(dfdate, \"%Y-%m-%d\")\n",
    "        udate = sdate + timedelta(days=1)\n",
    "        udate = udate.date()\n",
    "\n",
    "        try:\n",
    "            # call twitter api to fetch tweets\n",
    "            fetched_tweets = self.api.search(q = query, count = 100,  since = sdate, until=udate)\n",
    "\n",
    "            # parsing tweets one by one\n",
    "            for tweet in fetched_tweets:\n",
    "                # empty dictionary to store required params of a tweet\n",
    "                parsed_tweet = {}\n",
    "\n",
    "                day = pd.Timestamp(sdate)\n",
    "\n",
    "                # saving text of tweet\n",
    "                parsed_tweet['text'] = tweet.text\n",
    "\n",
    "                #Add weekend tweets to Monday (Set Monday date for weekends to accumulate later)\n",
    "                if day.dayofweek == 5:\n",
    "                    parsed_tweet['date_only'] = tweet.created_at.date() + timedelta(days=2)\n",
    "                elif day.dayofweek == 6:\n",
    "                    parsed_tweet['date_only'] = tweet.created_at.date() + timedelta(days=1)\n",
    "                else:\n",
    "                    parsed_tweet['date_only'] = tweet.created_at.date()\n",
    "\n",
    "                # saving sentiment of tweet\n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
    "\n",
    "                # appending parsed tweet to tweets list\n",
    "                if tweet.retweet_count > 0:\n",
    "                    # if tweet has retweets, ensure that it is appended only once\n",
    "                    if parsed_tweet not in tweets:\n",
    "                        tweets.append(parsed_tweet)\n",
    "                else:\n",
    "                    tweets.append(parsed_tweet)\n",
    "\n",
    "            # return parsed tweets\n",
    "            return tweets\n",
    "\n",
    "        except tweepy.TweepError as e:\n",
    "            TwitterError = e\n",
    "\n",
    "def main(tweet_obj, df):\n",
    "    # creating object of TwitterClient Class\n",
    "    api = TwitterClient()\n",
    "\n",
    "    # empty list to store all the tweets\n",
    "    tweets_all = []\n",
    "    dfdate = []\n",
    "\n",
    "    dfdates = df['date_time'].astype('datetime64[ns]')\n",
    "\n",
    "    for date in dfdates:\n",
    "        date=pd.to_datetime(date).date()\n",
    "        dfdate.append(date)\n",
    "\n",
    "    dfdates = pd.DataFrame(dfdate)\n",
    "    dfdates = dfdates.drop_duplicates(keep='last')\n",
    "    # calling function to get tweets\n",
    "    for i, date in dfdates.iterrows():\n",
    "        date1 = str(date)\n",
    "        date1 = date1[1:15]\n",
    "        \n",
    "        tweets = api.get_tweets(query = tweet_obj, count = 100, dfdate = date1 )\n",
    "        if tweets:\n",
    "            tweets_all.extend(tweets)\n",
    "\n",
    "        #Check for day, of Friday: Find tweets from the weekend as well:\n",
    "        day = pd.Timestamp(date1)\n",
    "        if day.dayofweek == 4:\n",
    "            saturday = date + timedelta(days=1)\n",
    "            sat = str(saturday)\n",
    "            sat = sat[1:15]\n",
    "            sunday   = saturday + timedelta(days=1)\n",
    "            sun = str(sunday)\n",
    "            sun = sun[1:15]\n",
    "\n",
    "            tweets = api.get_tweets(query = tweet_obj, count = 100, dfdate = sat )\n",
    "            if tweets:\n",
    "                tweets_all.extend(tweets)\n",
    "\n",
    "            tweets = api.get_tweets(query = tweet_obj, count = 100, dfdate = sun )\n",
    "            if tweets:\n",
    "                tweets_all.extend(tweets)         \n",
    "\n",
    "        # calling function to get tweets\n",
    "        tweets_df = pd.DataFrame(tweets_all)\n",
    "        tweets_df.to_csv(\"tweets.csv\")\n",
    "\n",
    "    if len(tweets_df) != 0:  \n",
    "        tweets_df.sort_values(by=['date_only','sentiment'], ascending=False, inplace=True)\n",
    "        tweets_df = tweets_df[['date_only','sentiment']]\n",
    "\n",
    "        tweets_df = tweets_df.groupby(['date_only','sentiment'], as_index=False).size()\n",
    "        tweets_df = tweets_df.pivot(index='date_only', columns='sentiment', values='size')\n",
    "\n",
    "        tweets_df['total_tw'] = (tweets_df['positive'] + tweets_df['negative'] + tweets_df['neutral'] )\n",
    "        tweets_df['pos_perc'] = (tweets_df['positive']/tweets_df['total_tw'])*100\n",
    "        tweets_df['neg_perc'] = (tweets_df['negative']/tweets_df['total_tw'])*100\n",
    "        tweets_df['neut_perc'] = (tweets_df['neutral']/tweets_df['total_tw'])*100\n",
    "        tweets_df['tw_weight'] = tweets_df['positive'] - tweets_df['negative']\n",
    "        tweets_df.to_csv(\"TwitterFeatures.csv\")\n",
    "    else:\n",
    "        print('Twitter API limit exceeded. Please try after sometime to have twitter sentiments as features.')\n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9715774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_delta_data(df, x_variable, y_variable, title):\n",
    "    plt.figure(figsize=(25, 25), dpi=80, facecolor = 'w', edgecolor = 'k')\n",
    "    plt.plot(df, x_variable, color='blue', label='Delta Opening Price')\n",
    "    plt.plot(df, y_variable, color = 'red', label = 'Delta Closing Price')\n",
    "\n",
    "    plt.title(title, fontsize = 40)\n",
    "    plt.xlabel('Time', fontsize=40)\n",
    "    plt.ylabel('Price', fontsize = 40)\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def plot_data(df, x_variable, y_variable, title):\n",
    "    plt.figure(figsize=(25, 25), dpi=80, facecolor = 'w', edgecolor = 'k')\n",
    "    plt.plot(df, x_variable, color='blue', label='Opening Price')\n",
    "    plt.plot(df, y_variable, color = 'red', label = 'Closing Price')\n",
    "\n",
    "    plt.title(title, fontsize = 40)\n",
    "    plt.xlabel('Time', fontsize=40)\n",
    "    plt.ylabel('Price', fontsize = 40)\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def plot_results(data):\n",
    "\n",
    "    data.plot.bar(x=\"Model\", y=\"RMSE\", rot=0, title= var.get() + \" Model Comparison\")\n",
    "    plt.ylabel(\"Root mean squared error (RMSE)\")\n",
    "    plt.grid()\n",
    "    plt.show(block=True)\n",
    "\n",
    "def plot_models(df, x_variable, y_variable, title):\n",
    "    plt.figure(figsize=(25, 25), dpi=80, facecolor = 'w', edgecolor = 'k')\n",
    "\n",
    "    plt.plot(df, x_variable, color='blue', label='Real Closing Price')\n",
    "    plt.plot(df, y_variable, color = 'red', label = 'Predicted Closing Price')\n",
    "\n",
    "    plt.title(title, fontsize = 30)\n",
    "    plt.xlabel('Time', fontsize=20)\n",
    "    plt.ylabel('Stock Closing Price', fontsize = 20)\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "004cee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Algorithm Code\n",
    "def algorithm(data):\n",
    "    outputlist = []\n",
    "    output_dataset = []\n",
    "    df_out = pd.DataFrame(output_dataset)\n",
    "\n",
    "    df_date = data['date_only']\n",
    "\n",
    "    #Drop extra columns\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data = data.drop(data.columns[[5, 6, 16, 17, 18, 19]], axis=1) \n",
    "    # data = data.drop('total_tw')\n",
    "\n",
    "    #Drop columns if commodity does not affect stock price  \n",
    "    commodity_threshold = cls_threshold(data)\n",
    "    # data = data.astype(int)\n",
    "\n",
    "    #split dataset in features and target variable\n",
    "    feature_cols = list(data.columns)\n",
    "    target_var = ['4. close']\n",
    "\n",
    "    X = data[feature_cols] # Features\n",
    "    y = data[target_var] # Target variable\n",
    "\n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "    num = len(X_test)\n",
    "    df_date = df_date[:num]\n",
    "\n",
    "    xtest_open = X_test['1. open']\n",
    "    df_out['StockOpeningPrice'] = xtest_open\n",
    "\n",
    "    df_out['Expected_CP'] = y_test\n",
    "\n",
    "    # Decision Tree\n",
    "    model = DecisionTreeRegressor(max_depth=5)\n",
    "    model = model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test) #Predicted Closing price of the stock\n",
    "    desTr_Acc = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "    #Update in excel\n",
    "    df_out['DecTree_CP_Pred'] = y_pred\n",
    "    plot_models(df = df_date,\n",
    "            x_variable = y_test, \n",
    "            y_variable = y_pred, \n",
    "            title = var.get() + \":Decision Tree\")\n",
    "\n",
    "    # saving the output\n",
    "    output = {}\n",
    "    output['Model'] = 'DecisionTree'\n",
    "    output['RMSE'] = desTr_Acc\n",
    "    outputlist.append(output)\n",
    "\n",
    "    #Knn Regression\n",
    "    model = neighbors.KNeighborsRegressor()\n",
    "    model = model.fit(X_train,y_train)                \n",
    "    y_pred = model.predict(X_test) #Predicted Closing price of the stock\n",
    "    knn_Acc = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "    #Update in excel\n",
    "    df_out['knn_CP_Pred'] = y_pred\n",
    "    plot_models(df = df_date,\n",
    "            x_variable = y_test, \n",
    "            y_variable = y_pred, \n",
    "            title = var.get() + \":KnnRegression\")\n",
    "\n",
    "    # saving the output\n",
    "    output = {}\n",
    "    output['Model'] = 'knnRegres'\n",
    "    output['RMSE'] = knn_Acc\n",
    "    outputlist.append(output)    \n",
    "\n",
    "    #Random Forest\n",
    "    ##grid = {'n_estimators': [200], 'max_depth': [3], 'max_features': [4, 8], 'random_state': [42]}\n",
    "    model=RandomForestRegressor(n_estimators=100) #(grid)\n",
    "    model = model.fit(X_train,y_train.values.ravel())\n",
    "    y_pred = model.predict(X_test) #Predicted Closing price of the stock\n",
    "    RanForr_Acc = metrics.mean_absolute_percentage_error(y_test, y_pred)    \n",
    "    #Update in excel\n",
    "    df_out['RanFor_CP_Pred'] = y_pred\n",
    "    plot_models(df = df_date,\n",
    "            x_variable = y_test, \n",
    "            y_variable = y_pred, \n",
    "            title = var.get() + \":Random Forest Regressor\")\n",
    "\n",
    "    # saving the output\n",
    "    output = {}\n",
    "    output['Model'] = 'RandomForest'\n",
    "    output['RMSE'] = RanForr_Acc\n",
    "    outputlist.append(output) \n",
    "\n",
    "    #Support Vector Regressor\n",
    "    X = X_train\n",
    "    y = y_train\n",
    "\n",
    "    sc_X = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    X = sc_X.fit_transform(X)\n",
    "    y = sc_y.fit_transform(y)\n",
    "\n",
    "    regressor = SVR(kernel = 'rbf')#'sigmoid')#'poly')\n",
    "    regressor.fit(X, y)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    y_pred = sc_y.inverse_transform(y_pred)\n",
    "    SVR_Acc = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    #Update in excel\n",
    "    df_out['SVR_CP_Pred'] = y_pred\n",
    "    plot_models(df = df_date,\n",
    "            x_variable = y_test, \n",
    "            y_variable = y_pred, \n",
    "            title = var.get() + \":Support Vector Regressor\")\n",
    "\n",
    "    # saving the output\n",
    "    output = {}\n",
    "    output['Model'] = 'SVR'\n",
    "    output['RMSE'] = SVR_Acc\n",
    "    outputlist.append(output)\n",
    "\n",
    "    #Find profit or loss\n",
    "    df_out['DT_Analysis'] = ''\n",
    "    df_out.loc[df_out.DecTree_CP_Pred > df_out.StockOpeningPrice, \"DT_Analysis\"] = 'Profit'\n",
    "    df_out.loc[df_out.DecTree_CP_Pred < df_out.StockOpeningPrice, \"DT_Analysis\"] = 'Loss'\n",
    "\n",
    "    df_out['Knn_Analysis'] = ''    \n",
    "    df_out.loc[df_out.knn_CP_Pred > df_out.StockOpeningPrice, \"Knn_Analysis\"] = 'Profit'\n",
    "    df_out.loc[df_out.knn_CP_Pred < df_out.StockOpeningPrice, \"Knn_Analysis\"] = 'Loss'\n",
    "\n",
    "    df_out['RF_Analysis'] = ''\n",
    "    df_out.loc[df_out.RanFor_CP_Pred > df_out.StockOpeningPrice, \"RF_Analysis\"] = 'Profit'\n",
    "    df_out.loc[df_out.RanFor_CP_Pred < df_out.StockOpeningPrice, \"RF_Analysis\"] = 'Loss'\n",
    "\n",
    "    df_out['SVR_Analysis'] = ''\n",
    "    df_out.loc[df_out.SVR_CP_Pred > df_out.StockOpeningPrice, \"SVR_Analysis\"] = 'Profit'\n",
    "    df_out.loc[df_out.SVR_CP_Pred < df_out.StockOpeningPrice, \"SVR_Analysis\"] = 'Loss'\n",
    "\n",
    "    df_out['Expected_Analysis'] = ''\n",
    "    df_out.loc[df_out.Expected_CP > df_out.StockOpeningPrice, \"Expected_Analysis\"] = 'Profit'\n",
    "    df_out.loc[df_out.Expected_CP < df_out.StockOpeningPrice, \"Expected_Analysis\"] = 'Loss'    \n",
    "\n",
    "    df_out.to_csv(\"AlgorithmResults.csv\")\n",
    "\n",
    "    #Best Model Analysis\n",
    "    dt_f1 = f1_score(df_out.Expected_Analysis, df_out.DT_Analysis, average=None)\n",
    "    knn_f1 = f1_score(df_out.Expected_Analysis, df_out.Knn_Analysis, average=None)\n",
    "    rf_f1 = f1_score(df_out.Expected_Analysis, df_out.RF_Analysis, average=None)\n",
    "    svr_f1 = f1_score(df_out.Expected_Analysis, df_out.SVR_Analysis, average=None)\n",
    "\n",
    "    max_f1 = (max(dt_f1[0], knn_f1[0], rf_f1[0], svr_f1[0]))\n",
    "\n",
    "    dt_acc = accuracy_score(df_out.Expected_Analysis , df_out.DT_Analysis) * 100\n",
    "    knn_acc = accuracy_score(df_out.Expected_Analysis, df_out.Knn_Analysis) * 100\n",
    "    rf_acc = accuracy_score(df_out.Expected_Analysis, df_out.RF_Analysis) * 100\n",
    "    svr_acc = accuracy_score(df_out.Expected_Analysis, df_out.SVR_Analysis) * 100\n",
    "\n",
    "    if max_f1 == dt_f1[0]:\n",
    "        best_model = 'DecisionTree'\n",
    "    elif max_f1 == knn_f1[0]:\n",
    "        best_model = 'K-NearestNeighbors'\n",
    "    elif max_f1 == rf_f1[0]:\n",
    "        best_model = 'RandomForest'\n",
    "    elif max_f1 == svr_f1[0]:\n",
    "        best_model = 'SupportVectorRegressor'\n",
    "\n",
    "    output = pd.DataFrame(outputlist)\n",
    "    output.insert(loc=2, column = 'F1-Score', value = [dt_f1[0], knn_f1[0], rf_f1[0], svr_f1[0]])\n",
    "    output.insert(loc=3, column = 'Accuracy', value = [dt_acc, knn_acc, rf_acc, svr_acc])\n",
    "    print(output)\n",
    "\n",
    "    # Note - RMSE is inversely proportional to F1-Score\n",
    "    print('Best Model is: ' + best_model + ' with F1-Score: ' + str(max_f1) )\n",
    "    plot_results(output) \n",
    "\n",
    "    return data, best_model, X_train, y_train, df_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9088d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, best_model, X_train, y_train, dfdate):\n",
    "\n",
    "    today = date.today()\n",
    "    dfdate = dfdate.shift()\n",
    "    dfdate.iloc[0] = today\n",
    "    dfdate = dfdate[:4]\n",
    "\n",
    "    data = data.shift()\n",
    "    data.iloc[0] = data.iloc[1]\n",
    "    data['1. open'].iloc[0] = data['4. close'].iloc[1]\n",
    "\n",
    "    if best_model == 'DecisionTree':\n",
    "        model = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "    elif best_model == 'K-NearestNeighbors':\n",
    "        model = neighbors.KNeighborsRegressor()\n",
    "\n",
    "    elif best_model == 'RandomForest':\n",
    "        model=RandomForestRegressor(n_estimators=100)\n",
    "    \n",
    "    test_rows = data[:4]\n",
    "\n",
    "    model = model.fit(X_train,y_train)\n",
    "    CP_Pred = model.predict(test_rows)\n",
    "\n",
    "    test_rows['Predicted'] = CP_Pred\n",
    "    test_rows = test_rows[['1. open', '4. close','Predicted']]\n",
    "    test_rows.to_csv(\"Prediction.csv\")\n",
    "\n",
    "    CP_actual = test_rows['4. close']\n",
    "\n",
    "    #Compare current date's opening and closing price and check for profit or loss\n",
    "    if test_rows['1. open'].iloc[0] > test_rows['Predicted'].iloc[0]:\n",
    "        print(\"Loss: Stock Opening Price is higher than the predicted Closing Price.\")\n",
    "    else:\n",
    "        print(\"Profit: Predicted Closing Price is higher than the Stock Opening Price.\")\n",
    "\n",
    "    #Plot Graph comparing actual and predicted closing price for past 4 days\n",
    "    plot_models(df = dfdate,\n",
    "            x_variable = CP_actual, \n",
    "            y_variable = CP_Pred, \n",
    "            title =\"Actual and \" + var.get() +  \" Predicted closing price for past 4 days Comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2cfb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Extraction, Feature Enginnering and Time-Series application\n",
    "ts_data = timeseriesfunc(var.get(),var2.get())\n",
    "\n",
    "## Plot Opening Price, Closing Price and their Delta values\n",
    "df_date = ts_data['date_only']\n",
    "x_delta = ts_data['Delta_OP']\n",
    "y_delta = ts_data['Delta_CP']\n",
    "x = ts_data['1. open']\n",
    "y = ts_data['4. close']\n",
    "\n",
    "plot_data(df = df_date,\n",
    "        x_variable = x, \n",
    "        y_variable = y, \n",
    "        title = \"Prices of \" + var.get() + \" : \" + var2.get() + \" Interval\")\n",
    "\n",
    "plot_delta_data(df = df_date,\n",
    "        x_variable = x_delta, \n",
    "        y_variable = y_delta, \n",
    "        title = \"Delta Prices of \" + var.get() + \" : \" + var2.get() + \" Interval\")\n",
    "\n",
    "# # Candlestick Graph\n",
    "df1 = pd.DataFrame(ts_data)\n",
    "fig = go.Figure(data=[go.Candlestick(x=df1[\"date_time\"],\n",
    "                open=df1['1. open'],\n",
    "                high=df1['2. high'],\n",
    "                low=df1['3. low'],\n",
    "                close=df1['4. close'])])\n",
    "fig.update_layout(title= var.get() + \" : \" + var2.get() + \" Interval\")\n",
    "fig.show()\n",
    "\n",
    "## ML Algorithms Application\n",
    "data, best_model, X_train, y_train, dfdate = algorithm(ts_data)\n",
    "\n",
    "## Prediction of the Stock Price movement\n",
    "predict(data, best_model, X_train, y_train, dfdate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
